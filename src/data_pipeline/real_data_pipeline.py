"""
–ü–æ–ª–Ω—ã–π pipeline –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: CHIRPS + ERA5 + MODIS
–¢—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:
1. CDS API –¥–ª—è ERA5 (~/.cdsapirc)
2. Google Earth Engine –¥–ª—è MODIS
3. NASA Earthdata –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤

–ó–∞–ø—É—Å–∫: python -m src.data_pipeline.real_data_pipeline
"""

import os
import sys
import time
from pathlib import Path
import warnings
import json
import datetime as dt
from typing import Optional, Dict, Any

import numpy as np
import pandas as pd
import xarray as xr
import requests
from scipy.stats import gamma, norm

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ Google Earth Engine
try:
    import ee
    import geemap
    GEE_AVAILABLE = True
    print("‚úÖ Google Earth Engine –¥–æ—Å—Ç—É–ø–µ–Ω")
except ImportError:
    GEE_AVAILABLE = False
    print("‚ö† Google Earth Engine –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

warnings.filterwarnings("ignore")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
YEARS = range(2020, 2021)  # –ü–æ–ª–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
OUT_DIR = Path("data/raw")
PROC_DIR = Path("data/processed")
ZARR_OUT = PROC_DIR / "real_agro_cube.zarr"

# –í—Å–µ —Ä–µ–≥–∏–æ–Ω—ã –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
REGIONS = {
    "us_plains": (35, 48, -104, -90),      # –°–®–ê - –í–µ–ª–∏–∫–∏–µ —Ä–∞–≤–Ω–∏–Ω—ã
    "br_cerrado": (-20, -6, -62, -46),     # –ë—Ä–∞–∑–∏–ª–∏—è - –°–µ—Ä—Ä–∞–¥–æ  
    "in_ganga": (21, 31, 73, 90),          # –ò–Ω–¥–∏—è - –ì–∞–Ω–≥
    "ru_steppe": (50, 55, 37, 47),         # –†–æ—Å—Å–∏—è - –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ-–ß–µ—Ä–Ω–æ–∑–µ–º–Ω—ã–π
}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π bbox –æ—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏–π –≤—Å–µ —Ä–µ–≥–∏–æ–Ω—ã
LAT_MIN = min(r[0] for r in REGIONS.values()) - 1
LAT_MAX = max(r[1] for r in REGIONS.values()) + 1  
LON_MIN = min(r[2] for r in REGIONS.values()) - 1
LON_MAX = max(r[3] for r in REGIONS.values()) + 1

GLOBAL_BOUNDS = {
    'lat_min': LAT_MIN,
    'lat_max': LAT_MAX,
    'lon_min': LON_MIN,
    'lon_max': LON_MAX
}

class GoogleEarthEngineSetup:
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Google Earth Engine"""
    
    @staticmethod
    def initialize_gee(project_id: Optional[str] = None) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GEE"""
        if not GEE_AVAILABLE:
            return False
            
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å –ø—Ä–æ–µ–∫—Ç–æ–º
            if project_id:
                ee.Initialize(project=project_id)
                print(f"‚úÖ GEE –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –ø—Ä–æ–µ–∫—Ç–æ–º: {project_id}")
            else:
                ee.Initialize()
                print("‚úÖ GEE –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ GEE: {e}")
            print("\nüìã –î–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Google Earth Engine:")
            print("1. –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å: https://earthengine.google.com/")
            print("2. –°–æ–∑–¥–∞–π—Ç–µ Google Cloud Project: https://console.cloud.google.com/")
            print("3. –í–∫–ª—é—á–∏—Ç–µ Earth Engine API –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞")
            print("4. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install earthengine-api geemap")
            print("5. –í—ã–ø–æ–ª–Ω–∏—Ç–µ: earthengine authenticate")
            print("6. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é: export GEE_PROJECT_ID='your-project-id'")
            return False

class RealMODISDownloader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ —Ä–µ–∞–ª—å–Ω—ã—Ö MODIS –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ Google Earth Engine"""
    
    def __init__(self, global_bounds: Dict):
        self.global_bounds = global_bounds
        self.roi = ee.Geometry.Rectangle([
            global_bounds['lon_min'], global_bounds['lat_min'],
            global_bounds['lon_max'], global_bounds['lat_max']
        ])
        
    def download_modis_ndvi(self, years: range) -> Optional[xr.Dataset]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö MODIS NDVI –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤"""
        print("üõ∞ –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö MODIS NDVI —á–µ—Ä–µ–∑ Google Earth Engine...")
        print(f"üó∫ –ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ–±–ª–∞—Å—Ç—å: {self.global_bounds}")
        print(f"üìç –†–µ–≥–∏–æ–Ω—ã: {list(REGIONS.keys())}")
        
        # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–∞—Ç
        start_date = f"{years[0]}-01-01"
        end_date = f"{years[-1]}-12-31"
        
        print(f"üìÖ –ü–µ—Ä–∏–æ–¥: {start_date} - {end_date}")
        
        try:
            # MODIS Terra Vegetation Indices (MOD13A2) - 16-–¥–Ω–µ–≤–Ω—ã–µ –∫–æ–º–ø–æ–∑–∏—Ç—ã 1–∫–º
            modis = ee.ImageCollection("MODIS/061/MOD13A2") \
                .filterDate(start_date, end_date) \
                .filterBounds(self.roi) \
                .select(['NDVI', 'EVI', ])
            
            print(f"üìä –ù–∞–π–¥–µ–Ω–æ {modis.size().getInfo()} MODIS –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            
            if modis.size().getInfo() == 0:
                print("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö MODIS –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞")
                return None
            
            # –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            def process_modis(image):
                # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ NDVI –∏ EVI (scale factor = 0.0001)
                ndvi = image.select('NDVI').multiply(0.0001)
                evi = image.select('EVI').multiply(0.0001)
                
                # –ú–∞—Å–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞–¥–µ–∂–Ω—ã–µ –ø–∏–∫—Å–µ–ª–∏)
                quality = image.select('DetailedQA')
                good_pixels = quality.eq(0)  # 0 = —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å–∫—É
                ndvi_masked = ndvi.updateMask(good_pixels)
                evi_masked = evi.updateMask(good_pixels)
                
                return ee.Image.cat([
                    ndvi_masked.rename('ndvi'),
                    evi_masked.rename('evi')
                ]).copyProperties(image, ['system:time_start'])
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
            modis_processed = modis.map(process_modis)
            
            # –°–æ–∑–¥–∞–µ–º –º–µ—Å—è—á–Ω—ã–µ –∫–æ–º–ø–æ–∑–∏—Ç—ã
            def create_monthly_composite(year_month):
                year = ee.Number(year_month).divide(100).floor()
                month = ee.Number(year_month).mod(100)
                
                start = ee.Date.fromYMD(year, month, 1)
                end = start.advance(1, 'month')
                
                monthly = modis_processed.filterDate(start, end)
                
                return ee.Algorithms.If(
                    monthly.size().gt(0),
                    monthly.median().set({
                        'year': year,
                        'month': month,
                        'system:time_start': start.millis()
                    }),
                    None
                )
            
            # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –º–µ—Å—è—Ü–µ–≤
            months_list = []
            for year in years:
                for month in range(1, 13):
                    months_list.append(year * 100 + month)
            
            monthly_images = [create_monthly_composite(ym) for ym in months_list]
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è
            monthly_collection = ee.ImageCollection(
                ee.List(monthly_images).filter(ee.Filter.neq('item', None))
            )
            
            actual_count = monthly_collection.size().getInfo()
            print(f"üìä –°–æ–∑–¥–∞–Ω–æ {actual_count} –º–µ—Å—è—á–Ω—ã—Ö –∫–æ–º–ø–æ–∑–∏—Ç–æ–≤")
            
            if actual_count == 0:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –º–µ—Å—è—á–Ω—ã–µ –∫–æ–º–ø–æ–∑–∏—Ç—ã")
                return None
            
            # –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö
            return self._export_to_xarray(monthly_collection, years)
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ MODIS: {e}")
            return None
    
    def _export_to_xarray(self, collection: ee.ImageCollection, years: range) -> xr.Dataset:
        """–≠–∫—Å–ø–æ—Ä—Ç GEE –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ xarray"""
        print("üì¶ –≠–∫—Å–ø–æ—Ä—Ç MODIS –¥–∞–Ω–Ω—ã—Ö –≤ xarray...")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—É—é —Å–µ—Ç–∫—É –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤
        scale = 1000  # 1–∫–º –≤ –º–µ—Ç—Ä–∞—Ö
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –æ—Ö–≤–∞—Ç–∞
        lon_coords = np.arange(
            self.global_bounds['lon_min'], 
            self.global_bounds['lon_max'], 
            0.01  # ~1–∫–º
        )
        lat_coords = np.arange(
            self.global_bounds['lat_max'], 
            self.global_bounds['lat_min'], 
            -0.01  # –£–±—ã–≤–∞—é—â–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        )
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        time_coords = pd.date_range(
            f"{years[0]}-01-01", 
            f"{years[-1]}-12-31", 
            freq='MS'
        )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–∞—Å—Å–∏–≤—ã –¥–∞–Ω–Ω—ã—Ö
        ndvi_data = np.full((len(time_coords), len(lat_coords), len(lon_coords)), np.nan)
        evi_data = np.full((len(time_coords), len(lat_coords), len(lon_coords)), np.nan)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        img_list = collection.toList(collection.size())
        n_images = collection.size().getInfo()
        
        print(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ {n_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
        
        for i in range(min(n_images, len(time_coords))):
            try:
                print(f"  üìÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ {time_coords[i].strftime('%Y-%m')} ({i+1}/{n_images})")
                
                # –ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                img = ee.Image(img_list.get(i))
                
                # –≠–∫—Å–ø–æ—Ä—Ç —á–µ—Ä–µ–∑ geemap
                try:
                    # NDVI
                    ndvi_array = geemap.ee_to_numpy(
                        img.select('ndvi'),
                        region=self.roi,
                        scale=scale,
                        crs='EPSG:4326'
                    )
                    
                    # EVI  
                    evi_array = geemap.ee_to_numpy(
                        img.select('evi'),
                        region=self.roi,
                        scale=scale,
                        crs='EPSG:4326'
                    )
                    
                    if ndvi_array is not None and evi_array is not None:
                        # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                        if ndvi_array.shape != (len(lat_coords), len(lon_coords)):
                            from scipy.ndimage import zoom
                            zoom_factors = (
                                len(lat_coords) / ndvi_array.shape[0],
                                len(lon_coords) / ndvi_array.shape[1]
                            )
                            ndvi_array = zoom(ndvi_array, zoom_factors, order=1)
                            evi_array = zoom(evi_array, zoom_factors, order=1)
                        
                        ndvi_data[i] = ndvi_array
                        evi_data[i] = evi_array
                        
                        print(f"    ‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
                    else:
                        print(f"    ‚ö† –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ")
                        
                except Exception as export_error:
                    print(f"    ‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {export_error}")
                    continue
                    
            except Exception as img_error:
                print(f"    ‚ùå –û—à–∏–±–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img_error}")
                continue
        
        # –ü–æ–¥—Å—á–µ—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–µ—Å—è—Ü–µ–≤
        valid_ndvi = ~np.isnan(ndvi_data).all(axis=(1, 2))
        success_rate = valid_ndvi.sum() / len(time_coords) * 100
        
        print(f"üìä –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {valid_ndvi.sum()}/{len(time_coords)} –º–µ—Å—è—Ü–µ–≤ ({success_rate:.1f}%)")
        
        # –°–æ–∑–¥–∞–µ–º xarray Dataset
        modis_ds = xr.Dataset({
            'ndvi': (['time', 'latitude', 'longitude'], ndvi_data),
            'evi': (['time', 'latitude', 'longitude'], evi_data),
        }, coords={
            'time': time_coords,
            'latitude': lat_coords,
            'longitude': lon_coords,
        })
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        modis_ds.attrs.update({
            'title': 'Real MODIS NDVI/EVI from Google Earth Engine',
            'source': 'MODIS/061/MOD13A2',
            'description': 'Monthly composites of MODIS NDVI and EVI',
            'spatial_resolution': '1km',
            'temporal_resolution': 'monthly',
            'download_method': 'Google Earth Engine',
            'success_rate': f'{success_rate:.1f}%',
            'global_bounds': self.global_bounds,
            'regions_covered': list(REGIONS.keys())
        })
        
        print(f"‚úÖ MODIS –¥–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã: {dict(modis_ds.dims)}")
        return modis_ds

class CHIRPSDownloader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ —Ä–µ–∞–ª—å–Ω—ã—Ö CHIRPS –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤"""
    
    BASE_URL = "https://data.chc.ucsb.edu/products/CHIRPS-2.0/global_daily/netcdf/p25"
    
    @staticmethod
    def download_and_process(years: range, global_bounds: Dict, dest_dir: Path) -> xr.Dataset:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ CHIRPS –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤"""
        print("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö CHIRPS –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤...")
        print(f"üåç –ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ–±–ª–∞—Å—Ç—å: {global_bounds}")
        print(f"üìç –†–µ–≥–∏–æ–Ω—ã: {list(REGIONS.keys())}")
        
        datasets = []
        
        for year in years:
            dest_file = dest_dir / f"chirps_{year}.nc"
            
            if not dest_file.exists():
                url = f"{CHIRPSDownloader.BASE_URL}/chirps-v2.0.{year}.days_p25.nc"
                print(f"‚¨á –ó–∞–≥—Ä—É–∑–∫–∞ CHIRPS {year}...")
                
                try:
                    response = requests.get(url, stream=True, timeout=1800)  # 30 –º–∏–Ω—É—Ç
                    response.raise_for_status()
                    
                    total_size = int(response.headers.get('content-length', 0))
                    downloaded = 0
                    
                    with open(dest_file, "wb") as f:
                        for chunk in response.iter_content(chunk_size=1024*1024):
                            if chunk:
                                f.write(chunk)
                                downloaded += len(chunk)
                                
                                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 100MB
                                if downloaded % (100 * 1024 * 1024) == 0:
                                    if total_size > 0:
                                        progress = (downloaded / total_size) * 100
                                        print(f"    üì• {progress:.0f}%", end="", flush=True)
                    
                    file_size = dest_file.stat().st_size / (1024**2)
                    print(f" ‚úÖ ({file_size:.1f} MB)")
                    
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CHIRPS {year}: {e}")
                    continue
            else:
                file_size = dest_file.stat().st_size / (1024**2)
                print(f"üìÅ CHIRPS {year} —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω ({file_size:.1f} MB)")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª
            try:
                ds = xr.open_dataset(dest_file)
                datasets.append(ds)
                print(f"‚úÖ CHIRPS {year} –ø—Ä–æ—á–∏—Ç–∞–Ω")
            except Exception as e:
                print(f"‚ö† –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è CHIRPS {year}: {e}")
        
        if not datasets:
            raise RuntimeError("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å CHIRPS –¥–∞–Ω–Ω—ã–µ")
        
        print(f"üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ {len(datasets)} —Ñ–∞–π–ª–æ–≤ CHIRPS...")
        combined = xr.concat(datasets, dim="time")
        
        # –û–±—Ä–µ–∑–∫–∞ –ø–æ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤
        lat_slice = slice(global_bounds['lat_min'], global_bounds['lat_max'])
        if combined.latitude[0] > combined.latitude[-1]:
            lat_slice = slice(global_bounds['lat_max'], global_bounds['lat_min'])
            
        combined = combined.sel(
            latitude=lat_slice,
            longitude=slice(global_bounds['lon_min'], global_bounds['lon_max'])
        )
        
        # –ú–µ—Å—è—á–Ω—ã–µ —Å—É–º–º—ã
        print("üìä –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Å—è—á–Ω—ã—Ö —Å—É–º–º –æ—Å–∞–¥–∫–æ–≤...")
        monthly = combined.resample(time="1M").sum()
        
        print(f"‚úÖ CHIRPS –≥–æ—Ç–æ–≤: {dict(monthly.dims)}")
        print(f"üìä –í—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω: {monthly.time.min().values} - {monthly.time.max().values}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ —Ä–µ–≥–∏–æ–Ω–æ–≤
        print("üó∫ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–∫—Ä—ã—Ç–∏—è —Ä–µ–≥–∏–æ–Ω–æ–≤:")
        for region_name, (lat_min, lat_max, lon_min, lon_max) in REGIONS.items():
            try:
                region_data = monthly.sel(
                    latitude=slice(lat_min, lat_max),
                    longitude=slice(lon_min, lon_max)
                )
                if len(region_data.latitude) > 0 and len(region_data.longitude) > 0:
                    coverage = 1 - np.isnan(region_data['precip'].values).mean()
                    print(f"  {region_name}: {coverage*100:.1f}% –ø–æ–∫—Ä—ã—Ç–∏–µ, "
                          f"{len(region_data.latitude)}x{len(region_data.longitude)} –ø–∏–∫—Å–µ–ª–µ–π")
                else:
                    print(f"  {region_name}: ‚ùå –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
            except Exception as e:
                print(f"  {region_name}: ‚ö† –æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
        
        return monthly

class ERA5Downloader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ ERA5 –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤"""
    
    @staticmethod
    def check_and_download(years: range, global_bounds: Dict, dest_dir: Path) -> Optional[xr.Dataset]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ ERA5 –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤"""
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º CDS API
        cds_rc = Path.home() / ".cdsapirc"
        if not cds_rc.exists():
            print("‚ö† ERA5 –ø—Ä–æ–ø—É—â–µ–Ω: –Ω–µ—Ç ~/.cdsapirc")
            print("üí° –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª ~/.cdsapirc —Å –≤–∞—à–∏–º CDS API –∫–ª—é—á–æ–º")
            return None
            
        try:
            import cdsapi
        except ImportError:
            print("‚ö† ERA5 –ø—Ä–æ–ø—É—â–µ–Ω: –Ω–µ—Ç cdsapi")
            print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install cdsapi")
            return None
        
        era5_file = dest_dir / "era5_global_all_regions.nc"
        
        if era5_file.exists():
            print("üìÅ ERA5 —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
            return xr.open_dataset(era5_file)
        
        print("‚¨á –ó–∞–≥—Ä—É–∑–∫–∞ ERA5-Land –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤...")
        print(f"üåç –ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ–±–ª–∞—Å—Ç—å: {global_bounds}")
        
        client = cdsapi.Client()
        
        try:
            # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –±–æ–ª—å—à–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤
            client.retrieve(
                'reanalysis-era5-land',
                {
                    'variable': [
                        '2m_temperature',
                        'volumetric_soil_water_layer_1',
                        'potential_evaporation',
                        'total_precipitation'
                    ],
                    'year': [str(y) for y in years],
                    'month': [f'{m:02d}' for m in range(1, 13)],
                    'day': '15',  # –°–µ—Ä–µ–¥–∏–Ω–∞ –º–µ—Å—è—Ü–∞
                    'time': '12:00',
                    'area': [
                        global_bounds['lat_max'], global_bounds['lon_min'],
                        global_bounds['lat_min'], global_bounds['lon_max']
                    ],
                    'format': 'netcdf',
                },
                str(era5_file)
            )
            
            ds = xr.open_dataset(era5_file)
            print(f"‚úÖ ERA5 –≥–æ—Ç–æ–≤: {dict(ds.dims)}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ —Ä–µ–≥–∏–æ–Ω–æ–≤
            print("üó∫ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–∫—Ä—ã—Ç–∏—è ERA5 –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º:")
            for region_name, (lat_min, lat_max, lon_min, lon_max) in REGIONS.items():
                try:
                    region_data = ds.sel(
                        latitude=slice(lat_min, lat_max),
                        longitude=slice(lon_min, lon_max)
                    )
                    if len(region_data.latitude) > 0 and len(region_data.longitude) > 0:
                        print(f"  {region_name}: ‚úÖ {len(region_data.latitude)}x{len(region_data.longitude)} –ø–∏–∫—Å–µ–ª–µ–π")
                    else:
                        print(f"  {region_name}: ‚ùå –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
                except Exception as e:
                    print(f"  {region_name}: ‚ö† –æ—à–∏–±–∫–∞: {e}")
            
            return ds
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ ERA5: {e}")
            print("üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ CDS API –∏ –∫–≤–æ—Ç—ã")
            return None

def calculate_drought_indices(precip_data: np.ndarray) -> Dict[str, np.ndarray]:
    """–†–∞—Å—á–µ—Ç –∏–Ω–¥–µ–∫—Å–æ–≤ –∑–∞—Å—É—Ö–∏"""
    print("üßÆ –†–∞—Å—á–µ—Ç –∏–Ω–¥–µ–∫—Å–æ–≤ –∑–∞—Å—É—Ö–∏...")
    
    T, H, W = precip_data.shape
    
    # SPI-3
    spi3 = np.zeros((T, H, W))
    
    for t in range(3, T):
        rolling_sum = np.sum(precip_data[t-3:t], axis=0)
        
        for i in range(H):
            for j in range(W):
                # –ò—Å—Ç–æ—Ä–∏—è –¥–ª—è –ø–∏–∫—Å–µ–ª—è
                history = []
                for ht in range(3, t+1):
                    pixel_sum = np.sum(precip_data[ht-3:ht, i, j])
                    history.append(pixel_sum)
                
                if len(history) > 10:
                    mean_val = np.mean(history)
                    std_val = np.std(history)
                    if std_val > 0:
                        spi3[t, i, j] = (rolling_sum[i, j] - mean_val) / std_val
    
    spi3 = np.clip(spi3, -3, 3)
    
    return {'spi3': spi3}

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤"""
    print("üåç –ó–∞–≥—Ä—É–∑–∫–∞ –†–ï–ê–õ–¨–ù–´–• –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤: CHIRPS + ERA5 + MODIS")
    print("=" * 70)
    print(f"üìç –†–µ–≥–∏–æ–Ω—ã: {list(REGIONS.keys())}")
    print(f"üìÖ –ü–µ—Ä–∏–æ–¥: {YEARS[0]}-{YEARS[-1]}")
    print(f"üåç –ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ–±–ª–∞—Å—Ç—å: {GLOBAL_BOUNDS}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    gee_project = os.getenv('GEE_PROJECT_ID')
    if not gee_project:
        print("‚ö† –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è GEE_PROJECT_ID –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
        print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: export GEE_PROJECT_ID='your-google-cloud-project-id'")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    OUT_DIR.mkdir(parents=True, exist_ok=True)
    PROC_DIR.mkdir(parents=True, exist_ok=True)
    
    try:
        # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Google Earth Engine
        if GEE_AVAILABLE:
            gee_ready = GoogleEarthEngineSetup.initialize_gee(gee_project)
        else:
            gee_ready = False
        
        # 2. –ó–∞–≥—Ä—É–∑–∫–∞ CHIRPS (—Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤)
        print("\n1Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö CHIRPS –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤...")
        chirps_ds = CHIRPSDownloader.download_and_process(YEARS, GLOBAL_BOUNDS, OUT_DIR)
        
        # 3. –ó–∞–≥—Ä—É–∑–∫–∞ MODIS (—Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ GEE –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤)
        print("\n2Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö MODIS –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤...")
        if gee_ready:
            modis_downloader = RealMODISDownloader(GLOBAL_BOUNDS)
            modis_ds = modis_downloader.download_modis_ndvi(YEARS)
        else:
            print("‚ùå MODIS –ø—Ä–æ–ø—É—â–µ–Ω: GEE –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            modis_ds = None
        
        # 4. –ó–∞–≥—Ä—É–∑–∫–∞ ERA5 (–¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤)
        print("\n3Ô∏è‚É£ –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ ERA5 –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤...")
        era5_ds = ERA5Downloader.check_and_download(YEARS, GLOBAL_BOUNDS, OUT_DIR)
        
        # 5. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        print("\n4Ô∏è‚É£ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        # –ë–∞–∑–æ–≤—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ—Ç CHIRPS
        target_coords = {
            'time': chirps_ds.time,
            'latitude': chirps_ds.latitude,
            'longitude': chirps_ds.longitude
        }
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å CHIRPS
        final_vars = {
            'precipitation': (['time', 'latitude', 'longitude'], chirps_ds['precip'].values)
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º MODIS –µ—Å–ª–∏ –µ—Å—Ç—å
        if modis_ds is not None:
            modis_interp = modis_ds.interp(
                latitude=target_coords['latitude'],
                longitude=target_coords['longitude'],
                time=target_coords['time'],
                method='linear'
            )
            final_vars['ndvi'] = (['time', 'latitude', 'longitude'], modis_interp['ndvi'].values)
            final_vars['evi'] = (['time', 'latitude', 'longitude'], modis_interp['evi'].values)
        
        # –î–æ–±–∞–≤–ª—è–µ–º ERA5 –µ—Å–ª–∏ –µ—Å—Ç—å
        if era5_ds is not None:
            era5_interp = era5_ds.interp(
                latitude=target_coords['latitude'],
                longitude=target_coords['longitude'],
                time=target_coords['time'],
                method='linear'
            )
            final_vars['temperature'] = (['time', 'latitude', 'longitude'], era5_interp['t2m'].values - 273.15)
            final_vars['soil_moisture'] = (['time', 'latitude', 'longitude'], era5_interp['swvl1'].values)
        
        # 6. –†–∞—Å—á–µ—Ç –∏–Ω–¥–µ–∫—Å–æ–≤ –∑–∞—Å—É—Ö–∏
        print("\n5Ô∏è‚É£ –†–∞—Å—á–µ—Ç –∏–Ω–¥–µ–∫—Å–æ–≤ –∑–∞—Å—É—Ö–∏...")
        drought_indices = calculate_drought_indices(chirps_ds['precip'].values)
        
        for idx_name, idx_data in drought_indices.items():
            final_vars[idx_name] = (['time', 'latitude', 'longitude'], idx_data)
        
        # 7. –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        final_ds = xr.Dataset(final_vars, coords=target_coords)
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        data_sources = {
            'precipitation': 'CHIRPS v2.0 (real)',
            'drought_indices': 'Calculated from CHIRPS'
        }
        
        if modis_ds is not None:
            data_sources['ndvi'] = 'MODIS MOD13A2 via Google Earth Engine (real)'
            data_sources['evi'] = 'MODIS MOD13A2 via Google Earth Engine (real)'
            
        if era5_ds is not None:
            data_sources['temperature'] = 'ERA5-Land reanalysis (real)'
            data_sources['soil_moisture'] = 'ERA5-Land reanalysis (real)'
            data_sources['potential_evaporation'] = 'ERA5-Land reanalysis (real)'
        
        final_ds.attrs.update({
            'title': 'Real Multi-Source Multi-Region Drought Dataset',
            'description': 'Combined real satellite and reanalysis data for multiple agricultural regions',
            'data_sources': data_sources,
            'regions': REGIONS,
            'region_bounds': REGION_BOUNDS,
            'global_bounds': GLOBAL_BOUNDS,
            'spatial_resolution': '0.25 degrees',
            'temporal_resolution': 'monthly',
            'time_range': f'{YEARS[0]}-{YEARS[-1]}',
            'creation_date': dt.datetime.now().isoformat(),
            })

        
        # 8. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º
        print("\n6Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º...")
        
        print("\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        for var in final_ds.data_vars:
            data = final_ds[var].values
            nan_pct = np.isnan(data).mean() * 100
            print(f"  {var}: {nan_pct:.1f}% NaN, –¥–∏–∞–ø–∞–∑–æ–Ω [{np.nanmin(data):.2f}, {np.nanmax(data):.2f}]")
        
        print("\nüó∫ –ü–æ–∫—Ä—ã—Ç–∏–µ –¥–∞–Ω–Ω—ã–º–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º:")
        for region_name, (lat_min, lat_max, lon_min, lon_max) in REGIONS.items():
            try:
                region_data = final_ds.sel(
                    latitude=slice(lat_min, lat_max),
                    longitude=slice(lon_min, lon_max)
                )
                
                if len(region_data.latitude) > 0 and len(region_data.longitude) > 0:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
                    print(f"  üìç {region_name}:")
                    print(f"    –†–∞–∑–º–µ—Ä: {len(region_data.latitude)}x{len(region_data.longitude)} –ø–∏–∫—Å–µ–ª–µ–π")
                    print(f"    –í—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω: {region_data.time.min().values} - {region_data.time.max().values}")
                    
                    for var in final_ds.data_vars:
                        if var in region_data.data_vars:
                            var_data = region_data[var].values
                            coverage = (1 - np.isnan(var_data).mean()) * 100
                            print(f"    {var}: {coverage:.1f}% –ø–æ–∫—Ä—ã—Ç–∏–µ")
                        
                else:
                    print(f"  üìç {region_name}: ‚ùå –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —ç—Ç–æ–º —Ä–µ–≥–∏–æ–Ω–µ")
                    
            except Exception as e:
                print(f"  üìç {region_name}: ‚ö† –æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
        
        # 9. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ {ZARR_OUT}...")
        final_ds.to_zarr(ZARR_OUT, mode='w')
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        file_size = ZARR_OUT.stat().st_size / (1024**2)  # MB
        print(f"\nüéâ –†–µ–∞–ª—å–Ω—ã–π –º—É–ª—å—Ç–∏—Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!")
        print(f"üìÅ –ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ: {ZARR_OUT}")
        print(f"üíΩ –†–∞–∑–º–µ—Ä: {file_size:.1f} MB")
        print(f"üìä –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ: {list(final_ds.data_vars.keys())}")
        print(f"üìê –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {dict(final_ds.dims)}")
        print(f"üìç –†–µ–≥–∏–æ–Ω—ã: {list(REGIONS.keys())}")
        print(f"üåç –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö:")
        for var, source in data_sources.items():
            print(f"  ‚Ä¢ {var}: {source}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ—Ç–¥–µ–ª—å–Ω–æ
        metadata_file = PROC_DIR / "dataset_metadata.json"
        metadata = {
            'regions': REGIONS,
            'global_bounds': GLOBAL_BOUNDS,
            'years': list(YEARS),
            'data_sources': data_sources,
            'variables': list(final_ds.data_vars.keys()),
            'dimensions': dict(final_ds.dims),
            'creation_date': dt.datetime.now().isoformat(),
            'file_size_mb': file_size
        }
        
        with open(metadata_file, 'w') as f:
            json.dump(metadata, f, indent=2, default=str)
        
        print(f"üìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_file}")
        print("\n‚úÖ –ì–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –Ω–∞ –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–∞—Ö!")
        
        return final_ds
        
    except KeyboardInterrupt:
        print("\n‚èπ –ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return None
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    main()