"""
–ú–µ—Ç—Ä–∏–∫–∏ –∏ —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–∞—Å—É—Ö–∏

–í–∫–ª—é—á–∞–µ—Ç:
- –†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (MAE, RMSE, R¬≤, MAPE)
- –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–∞—Å—É—Ö–∏
- –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ-–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
- –ö–ª–∏–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏
- –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∑–∞—Å—É—Ö–∏

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: from src.utils.metrics import DroughtMetrics
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union
from sklearn.metrics import (
    mean_absolute_error, mean_squared_error, r2_score,
    precision_score, recall_score, f1_score, accuracy_score,
    confusion_matrix, classification_report
)
from scipy import stats
from scipy.spatial.distance import pdist, squareform
from scipy.stats import pearsonr, spearmanr
import warnings

warnings.filterwarnings("ignore")

class DroughtMetrics:
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –Ω–∞–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–∞—Å—É—Ö–∏"""
    
    # –ü–æ—Ä–æ–≥–∏ –∑–∞—Å—É—Ö–∏ –ø–æ SPI
    DROUGHT_THRESHOLDS = {
        'no_drought': (-0.5, 0.5),
        'mild_drought': (-1.0, -0.5),
        'moderate_drought': (-1.5, -1.0),
        'severe_drought': (-2.0, -1.5),
        'extreme_drought': (-np.inf, -2.0)
    }
    
    @staticmethod
    def regression_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:
        """–û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏"""
        
        # –£–¥–∞–ª—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
        mask = ~(np.isnan(y_true) | np.isnan(y_pred))
        y_true_clean = y_true[mask]
        y_pred_clean = y_pred[mask]
        
        if len(y_true_clean) == 0:
            return {name: np.nan for name in ['mae', 'rmse', 'r2', 'mape', 'smape', 'mase']}
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        mae = mean_absolute_error(y_true_clean, y_pred_clean)
        rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))
        r2 = r2_score(y_true_clean, y_pred_clean)
        
        # MAPE (Mean Absolute Percentage Error)
        mape = np.mean(np.abs((y_true_clean - y_pred_clean) / (y_true_clean + 1e-8))) * 100
        
        # SMAPE (Symmetric MAPE)
        smape = np.mean(2 * np.abs(y_pred_clean - y_true_clean) / 
                       (np.abs(y_true_clean) + np.abs(y_pred_clean) + 1e-8)) * 100
        
        # MASE (Mean Absolute Scaled Error)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º naive forecast (–ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ) –∫–∞–∫ –±–∞–∑–æ–≤—É—é –ª–∏–Ω–∏—é
        if len(y_true_clean) > 1:
            naive_errors = np.abs(y_true_clean[1:] - y_true_clean[:-1])
            mase = mae / (np.mean(naive_errors) + 1e-8)
        else:
            mase = np.nan
        
        return {
            'mae': float(mae),
            'rmse': float(rmse),
            'r2': float(r2),
            'mape': float(mape),
            'smape': float(smape),
            'mase': float(mase)
        }
    
    @staticmethod
    def drought_classification_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:
        """–ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–∞—Å—É—Ö–∏"""
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∑–∞—Å—É—Ö–∏
        y_true_cat = DroughtMetrics._spi_to_drought_category(y_true)
        y_pred_cat = DroughtMetrics._spi_to_drought_category(y_pred)
        
        # –£–¥–∞–ª—è–µ–º NaN
        mask = ~(pd.isna(y_true_cat) | pd.isna(y_pred_cat))
        y_true_clean = y_true_cat[mask]
        y_pred_clean = y_pred_cat[mask]
        
        if len(y_true_clean) == 0:
            return {name: np.nan for name in ['accuracy', 'precision', 'recall', 'f1']}
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        accuracy = accuracy_score(y_true_clean, y_pred_clean)
        
        # –î–ª—è –º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º macro average
        precision = precision_score(y_true_clean, y_pred_clean, average='macro', zero_division=0)
        recall = recall_score(y_true_clean, y_pred_clean, average='macro', zero_division=0)
        f1 = f1_score(y_true_clean, y_pred_clean, average='macro', zero_division=0)
        
        return {
            'accuracy': float(accuracy),
            'precision': float(precision),
            'recall': float(recall),
            'f1': float(f1)
        }
    
    @staticmethod
    def drought_detection_metrics(y_true: np.ndarray, y_pred: np.ndarray, 
                                threshold: float = -1.0) -> Dict[str, float]:
        """–ú–µ—Ç—Ä–∏–∫–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∑–∞—Å—É—Ö–∏ (–±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)"""
        
        # –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: –∑–∞—Å—É—Ö–∞/–Ω–µ –∑–∞—Å—É—Ö–∞
        drought_true = y_true < threshold
        drought_pred = y_pred < threshold
        
        # –£–¥–∞–ª—è–µ–º NaN
        mask = ~(np.isnan(y_true) | np.isnan(y_pred))
        drought_true_clean = drought_true[mask]
        drought_pred_clean = drought_pred[mask]
        
        if len(drought_true_clean) == 0:
            return {name: np.nan for name in ['pod', 'far', 'csi', 'bias']}
        
        # Confusion matrix
        tn, fp, fn, tp = confusion_matrix(drought_true_clean, drought_pred_clean).ravel()
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏
        pod = tp / (tp + fn) if (tp + fn) > 0 else 0  # Probability of Detection
        far = fp / (tp + fp) if (tp + fp) > 0 else 0  # False Alarm Ratio
        csi = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0  # Critical Success Index
        bias = (tp + fp) / (tp + fn) if (tp + fn) > 0 else 0  # Bias score
        
        return {
            'pod': float(pod),          # Probability of Detection
            'far': float(far),          # False Alarm Ratio
            'csi': float(csi),          # Critical Success Index
            'bias': float(bias)         # Bias score
        }
    
    @staticmethod
    def spatial_correlation(y_true: np.ndarray, y_pred: np.ndarray, 
                          coords: Optional[np.ndarray] = None) -> Dict[str, float]:
        """–ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏"""
        
        if y_true.ndim == 3:  # (time, lat, lon)
            # –°—Ä–µ–¥–Ω—è—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            correlations = []
            for t in range(y_true.shape[0]):
                true_flat = y_true[t].flatten()
                pred_flat = y_pred[t].flatten()
                
                mask = ~(np.isnan(true_flat) | np.isnan(pred_flat))
                if mask.sum() > 10:  # –ú–∏–Ω–∏–º—É–º —Ç–æ—á–µ–∫ –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
                    corr, _ = pearsonr(true_flat[mask], pred_flat[mask])
                    if not np.isnan(corr):
                        correlations.append(corr)
            
            spatial_corr = np.mean(correlations) if correlations else np.nan
            
        else:  # –ü–ª–æ—Å–∫–∏–π –º–∞—Å—Å–∏–≤
            mask = ~(np.isnan(y_true) | np.isnan(y_pred))
            if mask.sum() > 10:
                spatial_corr, _ = pearsonr(y_true[mask], y_pred[mask])
            else:
                spatial_corr = np.nan
        
        return {'spatial_correlation': float(spatial_corr)}
    
    @staticmethod
    def temporal_consistency(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:
        """–í—Ä–µ–º–µ–Ω–Ω–∞—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        
        if y_true.ndim == 1:
            # –û–¥–Ω–æ–º–µ—Ä–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥
            true_series = y_true
            pred_series = y_pred
        else:
            # –ú–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–π: —É—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤—É
            true_series = np.nanmean(y_true.reshape(y_true.shape[0], -1), axis=1)
            pred_series = np.nanmean(y_pred.reshape(y_pred.shape[0], -1), axis=1)
        
        # –£–¥–∞–ª—è–µ–º NaN
        mask = ~(np.isnan(true_series) | np.isnan(pred_series))
        true_clean = true_series[mask]
        pred_clean = pred_series[mask]
        
        if len(true_clean) < 3:
            return {'temporal_correlation': np.nan, 'trend_agreement': np.nan}
        
        # –í—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
        temp_corr, _ = pearsonr(true_clean, pred_clean)
        
        # –°–æ–≥–ª–∞—Å–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤ (–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø–µ—Ä–≤—ã—Ö —Ä–∞–∑–Ω–æ—Å—Ç–µ–π)
        true_diff = np.diff(true_clean)
        pred_diff = np.diff(pred_clean)
        
        if len(true_diff) > 0:
            trend_corr, _ = pearsonr(true_diff, pred_diff)
        else:
            trend_corr = np.nan
        
        return {
            'temporal_correlation': float(temp_corr),
            'trend_agreement': float(trend_corr)
        }
    
    @staticmethod
    def extreme_events_metrics(y_true: np.ndarray, y_pred: np.ndarray,
                             extreme_threshold: float = -2.0) -> Dict[str, float]:
        """–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π –∑–∞—Å—É—Ö–∏"""
        
        # –í—ã–¥–µ–ª—è–µ–º —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
        extreme_true = y_true < extreme_threshold
        extreme_pred = y_pred < extreme_threshold
        
        mask = ~(np.isnan(y_true) | np.isnan(y_pred))
        extreme_true_clean = extreme_true[mask]
        extreme_pred_clean = extreme_pred[mask]
        
        if len(extreme_true_clean) == 0 or extreme_true_clean.sum() == 0:
            return {name: np.nan for name in ['extreme_pod', 'extreme_far', 'extreme_intensity_error']}
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π
        tp = (extreme_true_clean & extreme_pred_clean).sum()
        fp = (~extreme_true_clean & extreme_pred_clean).sum()
        fn = (extreme_true_clean & ~extreme_pred_clean).sum()
        
        extreme_pod = tp / (tp + fn) if (tp + fn) > 0 else 0
        extreme_far = fp / (tp + fp) if (tp + fp) > 0 else 0
        
        # –û—à–∏–±–∫–∞ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π
        extreme_mask = extreme_true_clean
        if extreme_mask.sum() > 0:
            true_extreme_values = y_true[mask][extreme_mask]
            pred_extreme_values = y_pred[mask][extreme_mask]
            intensity_error = np.mean(np.abs(true_extreme_values - pred_extreme_values))
        else:
            intensity_error = np.nan
        
        return {
            'extreme_pod': float(extreme_pod),
            'extreme_far': float(extreme_far),
            'extreme_intensity_error': float(intensity_error)
        }
    
    @staticmethod
    def climatological_skill(y_true: np.ndarray, y_pred: np.ndarray,
                           climatology: Optional[np.ndarray] = None) -> Dict[str, float]:
        """–ö–ª–∏–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–∫–∏–ª–ª (–ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –∫–ª–∏–º–∞—Ç–∏—á–µ—Å–∫–æ–π –Ω–æ—Ä–º–æ–π)"""
        
        if climatology is None:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∫–∞–∫ –∫–ª–∏–º–∞—Ç–æ–ª–æ–≥–∏—é
            climatology = np.full_like(y_true, np.nanmean(y_true))
        
        # –£–¥–∞–ª—è–µ–º NaN
        mask = ~(np.isnan(y_true) | np.isnan(y_pred) | np.isnan(climatology))
        y_true_clean = y_true[mask]
        y_pred_clean = y_pred[mask]
        clim_clean = climatology[mask]
        
        if len(y_true_clean) == 0:
            return {'skill_score': np.nan, 'anomaly_correlation': np.nan}
        
        # Skill score (—É–ª—É—á—à–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–ª–∏–º–∞—Ç–æ–ª–æ–≥–∏–∏)
        mse_pred = np.mean((y_true_clean - y_pred_clean) ** 2)
        mse_clim = np.mean((y_true_clean - clim_clean) ** 2)
        
        skill_score = 1 - (mse_pred / mse_clim) if mse_clim > 0 else np.nan
        
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π
        true_anomaly = y_true_clean - clim_clean
        pred_anomaly = y_pred_clean - clim_clean
        
        if np.std(true_anomaly) > 0 and np.std(pred_anomaly) > 0:
            anomaly_corr, _ = pearsonr(true_anomaly, pred_anomaly)
        else:
            anomaly_corr = np.nan
        
        return {
            'skill_score': float(skill_score),
            'anomaly_correlation': float(anomaly_corr)
        }
    
    @staticmethod
    def drought_duration_metrics(y_true: np.ndarray, y_pred: np.ndarray,
                                threshold: float = -1.0) -> Dict[str, float]:
        """–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞—Å—É—Ö–∏"""
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥—ã –∑–∞—Å—É—Ö–∏
        drought_true = y_true < threshold
        drought_pred = y_pred < threshold
        
        # –ù–∞—Ö–æ–¥–∏–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–µ—Ä–∏–æ–¥–æ–≤ –∑–∞—Å—É—Ö–∏
        true_durations = DroughtMetrics._get_drought_durations(drought_true)
        pred_durations = DroughtMetrics._get_drought_durations(drought_pred)
        
        if len(true_durations) == 0 and len(pred_durations) == 0:
            return {name: np.nan for name in ['duration_bias', 'duration_correlation']}
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏—Ö –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        mean_true_duration = np.mean(true_durations) if true_durations else 0
        mean_pred_duration = np.mean(pred_durations) if pred_durations else 0
        
        duration_bias = (mean_pred_duration - mean_true_duration) / (mean_true_duration + 1e-8)
        
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (–µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ–±—ã—Ç–∏–π)
        if len(true_durations) >= 3 and len(pred_durations) >= 3:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
            max_duration = max(max(true_durations, default=0), max(pred_durations, default=0))
            if max_duration > 0:
                bins = np.arange(1, max_duration + 2)
                hist_true, _ = np.histogram(true_durations, bins=bins, density=True)
                hist_pred, _ = np.histogram(pred_durations, bins=bins, density=True)
                
                duration_corr, _ = pearsonr(hist_true, hist_pred)
            else:
                duration_corr = np.nan
        else:
            duration_corr = np.nan
        
        return {
            'duration_bias': float(duration_bias),
            'duration_correlation': float(duration_corr)
        }
    
    @staticmethod
    def comprehensive_evaluation(y_true: np.ndarray, y_pred: np.ndarray,
                                coords: Optional[np.ndarray] = None,
                                climatology: Optional[np.ndarray] = None) -> Dict[str, float]:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫"""
        
        metrics = {}
        
        # –†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics.update(DroughtMetrics.regression_metrics(y_true, y_pred))
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics.update(DroughtMetrics.drought_classification_metrics(y_true, y_pred))
        
        # –î–µ—Ç–µ–∫—Ü–∏—è –∑–∞—Å—É—Ö–∏
        metrics.update(DroughtMetrics.drought_detection_metrics(y_true, y_pred))
        
        # –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics.update(DroughtMetrics.spatial_correlation(y_true, y_pred, coords))
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics.update(DroughtMetrics.temporal_consistency(y_true, y_pred))
        
        # –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
        metrics.update(DroughtMetrics.extreme_events_metrics(y_true, y_pred))
        
        # –ö–ª–∏–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–∫–∏–ª–ª
        metrics.update(DroughtMetrics.climatological_skill(y_true, y_pred, climatology))
        
        # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞—Å—É—Ö–∏
        metrics.update(DroughtMetrics.drought_duration_metrics(y_true, y_pred))
        
        return metrics
    
    @staticmethod
    def _spi_to_drought_category(spi_values: np.ndarray) -> np.ndarray:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ SPI –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∑–∞—Å—É—Ö–∏"""
        categories = np.full_like(spi_values, np.nan, dtype=object)
        
        for category, (min_val, max_val) in DroughtMetrics.DROUGHT_THRESHOLDS.items():
            mask = (spi_values >= min_val) & (spi_values < max_val)
            categories[mask] = category
        
        return categories
    
    @staticmethod
    def _get_drought_durations(drought_mask: np.ndarray) -> List[int]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –ø–µ—Ä–∏–æ–¥–æ–≤ –∑–∞—Å—É—Ö–∏"""
        durations = []
        current_duration = 0
        
        for is_drought in drought_mask:
            if is_drought:
                current_duration += 1
            else:
                if current_duration > 0:
                    durations.append(current_duration)
                    current_duration = 0
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–µ—Ä–∏–æ–¥ –µ—Å–ª–∏ –æ–Ω –Ω–µ –∑–∞–∫–æ–Ω—á–∏–ª—Å—è
        if current_duration > 0:
            durations.append(current_duration)
        
        return durations

class MetricsAggregator:
    """–ê–≥—Ä–µ–≥–∞—Ç–æ—Ä –º–µ—Ç—Ä–∏–∫ –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤"""
    
    def __init__(self):
        self.experiments = {}
    
    def add_experiment(self, name: str, y_true: np.ndarray, y_pred: np.ndarray,
                      **kwargs) -> None:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞"""
        metrics = DroughtMetrics.comprehensive_evaluation(y_true, y_pred, **kwargs)
        self.experiments[name] = metrics
    
    def compare_experiments(self) -> pd.DataFrame:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤"""
        return pd.DataFrame(self.experiments).T
    
    def rank_experiments(self, primary_metric: str = 'mae', 
                        ascending: bool = True) -> pd.DataFrame:
        """–†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –ø–æ –º–µ—Ç—Ä–∏–∫–µ"""
        df = self.compare_experiments()
        return df.sort_values(primary_metric, ascending=ascending)
    
    def get_best_experiment(self, metric: str = 'mae', 
                           ascending: bool = True) -> Tuple[str, Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞"""
        ranking = self.rank_experiments(metric, ascending)
        best_name = ranking.index[0]
        return best_name, self.experiments[best_name]

class RegionalMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º"""
    
    @staticmethod
    def evaluate_by_regions(y_true: np.ndarray, y_pred: np.ndarray,
                          region_mask: np.ndarray, 
                          region_names: List[str]) -> Dict[str, Dict]:
        """–û—Ü–µ–Ω–∫–∞ –º–µ—Ç—Ä–∏–∫ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º"""
        
        regional_metrics = {}
        
        for i, region_name in enumerate(region_names):
            # –ú–∞—Å–∫–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞
            mask = region_mask == i
            
            if mask.sum() > 0:
                y_true_region = y_true[mask]
                y_pred_region = y_pred[mask]
                
                # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞
                metrics = DroughtMetrics.comprehensive_evaluation(y_true_region, y_pred_region)
                regional_metrics[region_name] = metrics
        
        return regional_metrics
    
    @staticmethod
    def compare_regional_performance(regional_metrics: Dict[str, Dict],
                                   metric: str = 'mae') -> pd.Series:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º"""
        
        performance = {}
        for region, metrics in regional_metrics.items():
            performance[region] = metrics.get(metric, np.nan)
        
        return pd.Series(performance).sort_values()

def calculate_model_confidence(y_pred_ensemble: List[np.ndarray]) -> np.ndarray:
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω—Å–∞–º–±–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∫–∞–∫ –º–µ—Ä–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏
    pred_array = np.array(y_pred_ensemble)
    confidence = 1 / (1 + np.std(pred_array, axis=0))
    
    return confidence

def bootstrap_metrics(y_true: np.ndarray, y_pred: np.ndarray,
                     n_bootstrap: int = 1000) -> Dict[str, Dict[str, float]]:
    """Bootstrap –æ—Ü–µ–Ω–∫–∞ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –¥–ª—è –º–µ—Ç—Ä–∏–∫"""
    
    n_samples = len(y_true)
    bootstrap_metrics = {metric: [] for metric in ['mae', 'rmse', 'r2']}
    
    for _ in range(n_bootstrap):
        # –°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ —Å –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ–º
        indices = np.random.choice(n_samples, n_samples, replace=True)
        y_true_boot = y_true[indices]
        y_pred_boot = y_pred[indices]
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = DroughtMetrics.regression_metrics(y_true_boot, y_pred_boot)
        
        for metric_name in bootstrap_metrics:
            bootstrap_metrics[metric_name].append(metrics[metric_name])
    
    # –í—ã—á–∏—Å–ª—è–µ–º –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
    confidence_intervals = {}
    for metric_name, values in bootstrap_metrics.items():
        values = np.array(values)
        confidence_intervals[metric_name] = {
            'mean': np.mean(values),
            'std': np.std(values),
            'ci_2.5': np.percentile(values, 2.5),
            'ci_97.5': np.percentile(values, 97.5)
        }
    
    return confidence_intervals

if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    print("üìä –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–∞—Å—É—Ö–∏")
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    np.random.seed(42)
    n_samples = 1000
    
    # –°–∏–º—É–ª—è—Ü–∏—è SPI –¥–∞–Ω–Ω—ã—Ö
    y_true = np.random.normal(0, 1, n_samples)  # SPI –∏–º–µ–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
    y_pred = y_true + np.random.normal(0, 0.3, n_samples)  # –î–æ–±–∞–≤–ª—è–µ–º —à—É–º
    
    # –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
    metrics = DroughtMetrics.comprehensive_evaluation(y_true, y_pred)
    
    print("üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏:")
    for metric_name, value in metrics.items():
        if not np.isnan(value):
            print(f"  {metric_name}: {value:.4f}")
    
    print("\n‚úÖ –°–∏—Å—Ç–µ–º–∞ –º–µ—Ç—Ä–∏–∫ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")