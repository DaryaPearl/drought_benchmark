#!/usr/bin/env python3
"""scaffold_project.py
====================================
Creates a clean directory layout and stub files for the
**Agroâ€‘Drought SPI Benchmark** project.

Run once from an empty folder:
$ python scaffold_project.py

It will create the tree:
.
â”œâ”€â”€ data/{raw,processed}
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ datamodules/agro_cube.py
â”‚   â”œâ”€â”€ models/{__init__,rf,tft}.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â””â”€â”€ train.py
â”œâ”€â”€ configs/{base,rf,tft}.yaml
â”œâ”€â”€ notebooks/exploration.ipynb (empty placeholder)
â”œâ”€â”€ results/
â””â”€â”€ README.md

Why a script and not a cookieâ€‘cutter?  So you can tweak the lists below
and regenerate if needed, while still tracking all templates in Git.
"""
from __future__ import annotations
import os, textwrap, pathlib

# ---------------------------------------------------------------------
# ðŸ—‚  Directory hierarchy
# ---------------------------------------------------------------------
DIRS: list[str] = [
    "data/raw",
    "data/processed",
    "src/datamodules",
    "src/models",
    "configs",
    "notebooks",
    "results",
]

# ---------------------------------------------------------------------
# ðŸ“„  File templates (path â†’ content)
# ---------------------------------------------------------------------
FILES: dict[str, str] = {
    "README.md": textwrap.dedent(
        """\
        # Agroâ€‘Drought SPI Benchmark

        *Structure autoâ€‘generated by* `scaffold_project.py`.

        ## Quick start
        ```bash
        # 1. create env
        pip install -r requirements.txt

        # 2. run baseline model
        python src/train.py model=rf
        ```
        """
    ),

    "requirements.txt": textwrap.dedent(
        """\
        pytorch-lightning>=2.2
        torchmetrics>=1.4
        scikit-learn>=1.4
        xgboost>=2.0
        lightgbm>=4.3
        earthformer
        strans-drought
        focal-tsmp
        pytorch-forecasting
        hydra-core>=1.3
        xarray
        zarr
        climate-indices
        google-cloud-storage
        """
    ),

    # ------------------- src/datamodules ---------------------------
    "src/datamodules/__init__.py": "",

    "src/datamodules/agro_cube.py": textwrap.dedent(
        """\
        "AgroDataModule: wraps xarray Zarr cube for PyTorch Lightning"
        from __future__ import annotations
        import pytorch_lightning as pl
        import xarray as xr
        import torch
        from torch.utils.data import DataLoader, TensorDataset

        class AgroDataModule(pl.LightningDataModule):
            def __init__(self, cfg):
                super().__init__()
                self.cfg = cfg
                self.ds: xr.Dataset | None = None

            def setup(self, stage=None):
                self.ds = xr.open_zarr(self.cfg.path)  # path to agro_cube.zarr

            def _split(self, years):
                ds_years = self.ds.sel(time=self.ds.time.dt.year.isin(years))
                X = torch.tensor(ds_years[self.cfg.features].to_array().values)
                y = torch.tensor(ds_years[self.cfg.target].values)
                return TensorDataset(X, y)

            def train_dataloader(self):
                return DataLoader(self._split(self.cfg.train_years), batch_size=self.cfg.batch_size, shuffle=True)

            def val_dataloader(self):
                return DataLoader(self._split(self.cfg.val_years), batch_size=self.cfg.batch_size)

            def test_dataloader(self):
                return DataLoader(self._split(self.cfg.test_years), batch_size=self.cfg.batch_size)
        """
    ),

    # ------------------- src/models ---------------------------
    "src/models/__init__.py": textwrap.dedent(
        """\
        from .rf import RandomForestModel
        try:
            from .tft import TFTModel
        except ImportError:
            TFTModel = None  # optional

        def get_model(cfg):
            name = cfg.name.lower()
            if name == "rf":
                return RandomForestModel(cfg)
            if name == "tft":
                if TFTModel is None:
                    raise ImportError("TFT dependencies missing")
                return TFTModel(cfg)
            raise ValueError(f"Unknown model: {name}")
        """
    ),

    "src/models/rf.py": textwrap.dedent(
        """\
        "Randomâ€‘Forest wrapper for Lightning"
        import pytorch_lightning as pl
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.metrics import mean_absolute_error, mean_squared_error
        import torch, numpy as np

        class RandomForestModel(pl.LightningModule):
            def __init__(self, cfg):
                super().__init__()
                self.save_hyperparameters(cfg)
                self.model = RandomForestRegressor(**cfg.params)

            def training_step(self, batch, batch_idx):
                X, y = batch
                X_np, y_np = X.numpy(), y.numpy()
                self.model.partial_fit(X_np, y_np)
                loss = torch.tensor(0.0)  # placeholder
                return loss

            def predict_step(self, batch, batch_idx):
                X, _ = batch
                return torch.tensor(self.model.predict(X.numpy()))

            def test_step(self, batch, batch_idx):
                X, y = batch
                preds = torch.tensor(self.model.predict(X.numpy()))
                mae = mean_absolute_error(y.numpy(), preds.numpy())
                rmse = mean_squared_error(y.numpy(), preds.numpy(), squared=False)
                self.log_dict({"test_mae": mae, "test_rmse": rmse})
        """
    ),

    "src/models/tft.py": textwrap.dedent(
        """\
        "Temporal Fusion Transformer wrapper"
        import pytorch_lightning as pl
        from pytorch_forecasting.models.temporal_fusion_transformer import TemporalFusionTransformer
        from pytorch_forecasting.data import TimeSeriesDataSet

        class TFTModel(pl.LightningModule):
            def __init__(self, cfg):
                super().__init__()
                self.cfg = cfg
                self.tft: TemporalFusionTransformer | None = None

            def setup(self, stage=None):
                # build TimeSeriesDataSet from DataModule's dataset
                dm = self.trainer.datamodule
                ds = dm.ds  # type: ignore
                ts = TimeSeriesDataSet.from_xarray(
                    ds,
                    time_idx="time",
                    target=self.cfg.target,
                    group_ids=["lat", "lon"],
                    max_prediction_length=self.cfg.max_pred_len,
                    max_encoder_length=self.cfg.max_enc_len,
                )
                self.tft = TemporalFusionTransformer.from_dataset(ts, **self.cfg.params)

            def forward(self, x):
                return self.tft(x)

            def configure_optimizers(self):
                return self.tft.configure_optimizers()
        """
    ),

    # ------------------- src/train.py ---------------------------
    "src/train.py": textwrap.dedent(
        """\
        "Main training entryâ€‘point (Hydraâ€‘enabled)"
        import hydra, pytorch_lightning as pl
        from omegaconf import DictConfig, OmegaConf
        from src.datamodules.agro_cube import AgroDataModule
        from src.models import get_model

        @hydra.main(version_base=None, config_path="../configs", config_name="base.yaml")
        def main(cfg: DictConfig):
            print(OmegaConf.to_yaml(cfg))
            dm = AgroDataModule(cfg.data)
            model = get_model(cfg.model)
            trainer = pl.Trainer(**cfg.trainer)
            trainer.fit(model, dm)
            trainer.test(model, dm)

        if __name__ == "__main__":
            main()
        """
    ),

    # ------------------- configs ---------------------------
    "configs/base.yaml": textwrap.dedent(
        """\
        # Common settings inherited by all experiments
        data:
          path: data/processed/agro_cube.zarr
          features: ["ndvi", "precip", "soil_moisture", "t2m"]
          target: spi
          batch_size: 256
          train_years: [2003, 2016]
          val_years: [2017, 2019]
          test_years: [2020, 2024]
        trainer:
          max_epochs: 10
          accelerator: auto
          log_every_n_steps: 50
        model:
          name: rf   # overridden from CLI
        """
    ),

    "configs/rf.yaml": textwrap.dedent(
        """\
        defaults:
          - base
        model:
          name: rf
          params:
            n_estimators: 300
            max_depth: null
            n_jobs: -1
        """
    ),

    "configs/tft.yaml": textwrap.dedent(
        """\
        defaults:
          - base
        model:
          name: tft
          target: spi
          max_enc_len: 12
          max_pred_len: 1
          params:
            hidden_size: 64
            attention_head_size: 4
            dropout: 0.1
        """
    ),
}

# ---------------------------------------------------------------------
# ðŸ”§  Scaffolding logic
# ---------------------------------------------------------------------

def write_file(path: str, content: str):
    path_obj = pathlib.Path(path)
    if not path_obj.exists():
        path_obj.parent.mkdir(parents=True, exist_ok=True)
        path_obj.write_text(content, encoding="utf-8")
        print(f"[+] created {path}")
    else:
        print(f"[ ] exists  {path}")


def main() -> None:
    for d in DIRS:
        os.makedirs(d, exist_ok=True)
        print(f"[+] dir {d}")

    for fp, text in FILES.items():
        write_file(fp, text)

    print("\nâœ… Project scaffold ready. Next: fill dataloader + models, then run:\n   python src/train.py model=rf\n")


if __name__ == "__main__":
    main()
