#!/usr/bin/env python3
"""
–ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–∞—Å—É—Ö–∏
–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω: —Å–±–æ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö ‚Üí –æ–±—É—á–µ–Ω–∏–µ ‚Üí –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python run_project.py --help                     # –°–ø—Ä–∞–≤–∫–∞
    python run_project.py --quick                    # –ë—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫
    python run_project.py --full                     # –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω
    python run_project.py --data-only                # –¢–æ–ª—å–∫–æ —Å–±–æ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    python run_project.py --train-only --model all  # –¢–æ–ª—å–∫–æ –æ–±—É—á–µ–Ω–∏–µ
    python run_project.py --custom --config my_config.yaml
"""

import argparse
import os
import sys
import subprocess
import json
import yaml
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
import time

class ProjectRunner:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–æ–º"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent
        self.start_time = time.time()
        self.config = {}
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        self.ensure_directories()
    
    def ensure_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –ø—Ä–æ–µ–∫—Ç–∞"""
        directories = [
            "data/raw",
            "data/processed", 
            "results",
            "logs",
            "configs",
            "checkpoints",
            "outputs"
        ]
        
        for dir_path in directories:
            (self.project_root / dir_path).mkdir(parents=True, exist_ok=True)
    
    def check_environment(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ Python –≤–µ—Ä—Å–∏–∏
        if sys.version_info < (3, 8):
            print("‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è Python 3.8 –∏–ª–∏ –≤—ã—à–µ")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        required_packages = [
            'numpy', 'pandas', 'xarray', 'torch', 'pytorch_lightning',
            'sklearn', 'matplotlib', 'requests'
        ]
        
        missing_packages = []
        for package in required_packages:
            try:
                __import__(package)
            except ImportError:
                missing_packages.append(package)
        
        if missing_packages:
            print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–∞–∫–µ—Ç—ã: {', '.join(missing_packages)}")
            print("üì¶ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏—Ö: pip install -r requirements.txt")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        netrc_file = Path.home() / ".netrc"
        if not netrc_file.exists():
            print("‚ö† –§–∞–π–ª ~/.netrc –Ω–µ –Ω–∞–π–¥–µ–Ω (–Ω—É–∂–µ–Ω –¥–ª—è NASA Earthdata)")
            print("üìù –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º:")
            print("machine urs.earthdata.nasa.gov")
            print("login YOUR_USERNAME")
            print("password YOUR_PASSWORD")
        
        print("‚úÖ –û–∫—Ä—É–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ")
        return True
    
    def load_config(self, config_path: Optional[str] = None) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        default_config = {
            "project": {
                "name": "drought_prediction_project",
                "version": "1.0.0",
                "description": "ML/AI system for agricultural drought prediction"
            },
            "data": {
                "years_range": [2003, 2024],
                "regions": {
                    "us_plains": [35, 48, -104, -90],
                    "br_cerrado": [-20, -6, -62, -46], 
                    "in_ganga": [21, 31, 73, 90],
                    "ru_steppe": [50, 55, 37, 47]
                },
                "variables": ["precipitation", "temperature", "ndvi", "soil_moisture"],
                "drought_indices": ["spi1", "spi3", "spi6", "spei3", "pdsi", "snepi"]
            },
            "training": {
                "sequence_length": 12,
                "prediction_horizon": 3,
                "train_years": [2003, 2016],
                "val_years": [2017, 2019],
                "test_years": [2020, 2024],
                "batch_size": 32,
                "max_epochs": 50,
                "early_stopping_patience": 10
            },
            "models": {
                "classical": ["linear_regression", "random_forest", "xgboost", "gradient_boosting"],
                "sota": ["earthformer", "convlstm", "tft", "unet"]
            },
            "output": {
                "save_predictions": True,
                "create_visualizations": True,
                "generate_report": True
            }
        }
        
        if config_path and Path(config_path).exists():
            print(f"üìã –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ {config_path}")
            with open(config_path, 'r') as f:
                custom_config = yaml.safe_load(f)
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            self.config = self._merge_configs(default_config, custom_config)
        else:
            self.config = default_config
            print("üìã –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
        
        return self.config
    
    def _merge_configs(self, default: Dict, custom: Dict) -> Dict:
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π"""
        merged = default.copy()
        for key, value in custom.items():
            if key in merged and isinstance(merged[key], dict) and isinstance(value, dict):
                merged[key] = self._merge_configs(merged[key], value)
            else:
                merged[key] = value
        return merged
    
    def save_config(self, config_path: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        config_path = Path(config_path)
        config_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(config_path, 'w') as f:
            yaml.dump(self.config, f, default_flow_style=False, indent=2)
        
        print(f"üíæ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {config_path}")
    
    def run_data_pipeline(self, quick_mode: bool = False) -> bool:
        """–ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å–±–æ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
        print("\n" + "="*60)
        print("üì¶ –≠–¢–ê–ü 1: –°–ë–û–†–ö–ê –î–ê–ù–ù–´–•")
        print("="*60)
        
        # –í –±—ã—Å—Ç—Ä–æ–º —Ä–µ–∂–∏–º–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π pipeline
        if quick_mode:
            print("‚ö° –ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º: —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –¥–∞–Ω–Ω—ã–µ
            data_path = Path("data/processed/real_agro_cube.zarr")
            if data_path.exists():
                print("üìÅ –î–∞–Ω–Ω—ã–µ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ")
                return True
            
            try:
                # –ó–∞–ø—É—Å–∫–∞–µ–º –±—ã—Å—Ç—Ä—ã–π pipeline
                result = subprocess.run([
                    sys.executable, "-m", "src.data_pipeline.quick_data_pipeline"
                ], cwd=self.project_root, capture_output=True, text=True, timeout=60)
                
                if result.returncode == 0:
                    print("‚úÖ –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–∑–¥–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")
                    print(result.stdout)
                    return True
                else:
                    print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö:")
                    print(result.stderr)
                    return False
                    
            except subprocess.TimeoutExpired:
                print("‚è± –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö")
                return False
            except Exception as e:
                print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
                return False
        
        # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º - –ø–æ–ª–Ω—ã–π pipeline
        else:
            data_script = self.project_root / "src" / "data_pipeline" / "real_data_pipeline.py"
            
            if not data_script.exists():
                print(f"‚ùå –°–∫—Ä–∏–ø—Ç —Å–±–æ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {data_script}")
                return False
            
            try:
                print("üöÄ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ pipeline —Å–±–æ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö...")
                
                env = os.environ.copy()
                if quick_mode:
                    env['QUICK_MODE'] = '1'
                
                result = subprocess.run([
                    sys.executable, "-m", "src.data_pipeline.real_data_pipeline"
                ], cwd=self.project_root, env=env, capture_output=True, text=True)
                
                if result.returncode == 0:
                    print("‚úÖ –°–±–æ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                    print(result.stdout)
                    return True
                else:
                    print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–∫–µ –¥–∞–Ω–Ω—ã—Ö:")
                    print(result.stderr)
                    return False
                    
            except Exception as e:
                print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ —Å–±–æ—Ä–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
                return False

    def run_training_pipeline(self, models: List[str], quick_mode: bool = False) -> bool:
        """–ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—É—á–µ–Ω–∏—è"""
        print("\n" + "="*60)
        print("ü§ñ –≠–¢–ê–ü 2: –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
        print("="*60)
        
        training_script = self.project_root / "src" / "complete_training_pipeline.py"
        
        if not training_script.exists():
            print(f"‚ùå –°–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω: {training_script}")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö
        data_path = self.project_root / "data" / "processed" / "real_agro_cube.zarr"
        if not data_path.exists():
            print(f"‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {data_path}")
            print("üí° –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–±–æ—Ä–∫—É –¥–∞–Ω–Ω—ã—Ö: --data-only")
            return False
        
        try:
            experiment_name = f"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            for model in models:
                print(f"\nüîß –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model}")
                
                cmd = [
                    sys.executable, "src/complete_training_pipeline.py",
                    "--model", model,
                    "--experiment", experiment_name
                ]
                
                if quick_mode:
                    cmd.append("--fast")
                    print("‚ö° –ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è")
                
                result = subprocess.run(cmd, cwd=self.project_root, 
                                      capture_output=True, text=True)
                
                if result.returncode == 0:
                    print(f"‚úÖ –ú–æ–¥–µ–ª—å {model} –æ–±—É—á–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                    # –ü–µ—á–∞—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –≤—ã–≤–æ–¥–∞
                    output_lines = result.stdout.split('\n')
                    for line in output_lines[-10:]:
                        if line.strip():
                            print(f"  {line}")
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ {model}:")
                    print(result.stderr)
                    return False
            
            print(f"\nüéâ –í—Å–µ –º–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã! –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: {experiment_name}")
            return True
            
        except Exception as e:
            print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}")
            return False
    
    def create_final_report(self) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        print("\n" + "="*60)
        print("üìä –≠–¢–ê–ü 3: –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        print("="*60)
        
        try:
            # –ü–æ–∏—Å–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
            results_dir = self.project_root / "results"
            experiments = list(results_dir.glob("exp_*"))
            
            if not experiments:
                print("‚ö† –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return False
            
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
            latest_exp = max(experiments, key=lambda x: x.stat().st_mtime)
            print(f"üìÅ –ê–Ω–∞–ª–∏–∑ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: {latest_exp.name}")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            results_file = latest_exp / "experiment_results.json"
            if results_file.exists():
                with open(results_file, 'r') as f:
                    results = json.load(f)
                
                # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
                self._create_executive_summary(results, latest_exp)
                self._create_technical_report(results, latest_exp)
                
                print("‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω")
                return True
            else:
                print("‚ùå –§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
            return False
    
    def _create_executive_summary(self, results: Dict, exp_dir: Path):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –¥–ª—è —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞"""
        summary_file = exp_dir / "executive_summary.md"
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("# –ö—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç: –°–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–∞—Å—É—Ö–∏\n\n")
            f.write(f"**–î–∞—Ç–∞:** {datetime.now().strftime('%d.%m.%Y')}\n")
            f.write(f"**–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç:** {exp_dir.name}\n\n")
            
            f.write("## üéØ –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n\n")
            
            # –ù–∞–π—Ç–∏ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
            best_model = self._find_best_model(results.get('results', {}))
            if best_model:
                f.write(f"### –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model['name']}\n")
                f.write(f"- **–¢–æ—á–Ω–æ—Å—Ç—å:** {best_model['accuracy']:.1%}\n")
                f.write(f"- **–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:** {best_model['training_time']:.1f} —Å–µ–∫\n")
                f.write(f"- **–¢–∏–ø:** {best_model['type']}\n\n")
            
            f.write("## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤\n\n")
            f.write("| –¢–∏–ø –º–æ–¥–µ–ª–∏ | –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç | –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è | –°–ª–æ–∂–Ω–æ—Å—Ç—å |\n")
            f.write("|------------|------------------|----------------|------------|\n")
            
            # –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏
            classical_results = results.get('results', {}).get('classical', {})
            if classical_results:
                best_classical = min(classical_results.items(), 
                                   key=lambda x: x[1].get('val_metrics', {}).get('mae', float('inf')))
                mae = best_classical[1].get('val_metrics', {}).get('mae', 0)
                time_val = best_classical[1].get('training_time', 0)
                f.write(f"| –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ ML | MAE: {mae:.4f} | {time_val:.1f}s | –ù–∏–∑–∫–∞—è |\n")
            
            # SOTA –º–æ–¥–µ–ª–∏
            sota_models = ['earthformer', 'convlstm', 'tft', 'unet']
            for model_name in sota_models:
                if model_name in results.get('results', {}):
                    model_res = results['results'][model_name]
                    if isinstance(model_res, dict) and 'error' not in model_res:
                        val_loss = model_res.get('val_metrics', {}).get('final_val_loss', 0)
                        time_val = model_res.get('training_time', 0)
                        f.write(f"| {model_name.upper()} | Loss: {val_loss:.4f} | {time_val:.1f}s | –í—ã—Å–æ–∫–∞—è |\n")
            
            f.write("\n## üîç –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n\n")
            if best_model:
                if best_model['type'] == 'classical':
                    f.write("- ‚úÖ **–î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ ML –º–æ–¥–µ–ª–∏\n")
                    f.write("- ‚ö° **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:** –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ, –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å\n")
                    f.write("- üéØ **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** –û–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∑–∞—Å—É—Ö–∏\n\n")
                else:
                    f.write("- üöÄ **–î–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ SOTA –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n")
                    f.write("- üìà **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:** –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å, —Ä–∞–±–æ—Ç–∞ —Å –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏\n") 
                    f.write("- üî¨ **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ\n\n")
            
            f.write("## üìà –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏\n\n")
            f.write("1. –í–∞–ª–∏–¥–∞—Ü–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n")
            f.write("2. –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞\n")
            f.write("3. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏\n")
            f.write("4. –°–±–æ—Ä –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n")
    
    def _create_technical_report(self, results: Dict, exp_dir: Path):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        tech_file = exp_dir / "technical_report.md"
        
        with open(tech_file, 'w', encoding='utf-8') as f:
            f.write("# –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç: –°–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–∞—Å—É—Ö–∏\n\n")
            
            f.write("## üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n\n")
            config = results.get('config', {})
            f.write("```yaml\n")
            f.write(yaml.dump(config, default_flow_style=False))
            f.write("```\n\n")
            
            f.write("## üìä –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n\n")
            
            # –ü–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
            model_results = results.get('results', {})
            for model_name, model_data in model_results.items():
                f.write(f"### {model_name.upper()}\n\n")
                
                if isinstance(model_data, dict) and 'error' not in model_data:
                    if model_name == 'classical':
                        f.write("#### –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏ ML\n\n")
                        f.write("| –ú–æ–¥–µ–ª—å | Train MAE | Val MAE | Val RMSE | Val R¬≤ | –í—Ä–µ–º—è (—Å) |\n")
                        f.write("|--------|-----------|---------|----------|--------|----------|\n")
                        
                        for sub_model, sub_data in model_data.items():
                            if isinstance(sub_data, dict):
                                train_metrics = sub_data.get('train_metrics', {})
                                val_metrics = sub_data.get('val_metrics', {})
                                f.write(f"| {sub_model} | "
                                       f"{train_metrics.get('mae', 'N/A'):.4f} | "
                                       f"{val_metrics.get('mae', 'N/A'):.4f} | "
                                       f"{val_metrics.get('rmse', 'N/A'):.4f} | "
                                       f"{val_metrics.get('r2', 'N/A'):.4f} | "
                                       f"{sub_data.get('training_time', 'N/A'):.1f} |\n")
                    else:
                        f.write("#### –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è\n\n")
                        train_metrics = model_data.get('train_metrics', {})
                        val_metrics = model_data.get('val_metrics', {})
                        test_metrics = model_data.get('test_metrics', {})
                        
                        f.write(f"- **–§–∏–Ω–∞–ª—å–Ω–∞—è –ø–æ—Ç–µ—Ä—è –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏:** {train_metrics.get('final_train_loss', 'N/A')}\n")
                        f.write(f"- **–§–∏–Ω–∞–ª—å–Ω–∞—è –ø–æ—Ç–µ—Ä—è –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:** {val_metrics.get('final_val_loss', 'N/A')}\n")
                        f.write(f"- **–õ—É—á—à–∞—è –ø–æ—Ç–µ—Ä—è –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:** {val_metrics.get('best_val_loss', 'N/A')}\n")
                        f.write(f"- **–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:** {model_data.get('training_time', 'N/A'):.1f} —Å–µ–∫\n")
                        
                        if test_metrics:
                            f.write(f"- **–¢–µ—Å—Ç–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:** {test_metrics}\n")
                        
                        f.write(f"- **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏:**\n")
                        model_config = model_data.get('model_config', {})
                        for key, value in model_config.items():
                            f.write(f"  - {key}: {value}\n")
                else:
                    f.write(f"‚ùå **–û—à–∏–±–∫–∞:** {model_data.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}\n")
                
                f.write("\n")
            
            f.write("## üí° –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≤—ã–≤–æ–¥—ã\n\n")
            f.write("### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n")
            f.write("- –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n")
            f.write("- SOTA –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Ç—Ä–µ–±—É—é—Ç –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ\n")
            f.write("- –ù–µ–æ–±—Ö–æ–¥–∏–º–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n\n")
            
            f.write("### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é\n")
            f.write("1. –£–≤–µ–ª–∏—á–∏—Ç—å –æ–±—ä–µ–º –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n")
            f.write("2. –î–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n")
            f.write("3. –ü—Ä–æ–≤–µ—Å—Ç–∏ –±–æ–ª–µ–µ —Ç—â–∞—Ç–µ–ª—å–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n")
            f.write("4. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã\n")
    
    def _find_best_model(self, results: Dict) -> Optional[Dict]:
        """–ü–æ–∏—Å–∫ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º"""
        best_model = None
        best_score = float('inf')
        
        for model_name, model_data in results.items():
            if isinstance(model_data, dict) and 'error' not in model_data:
                if model_name == 'classical':
                    # –î–ª—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π –∏—â–µ–º –ª—É—á—à–∏–π MAE
                    for sub_model, sub_data in model_data.items():
                        if isinstance(sub_data, dict):
                            mae = sub_data.get('val_metrics', {}).get('mae', float('inf'))
                            if mae < best_score:
                                best_score = mae
                                best_model = {
                                    'name': sub_model,
                                    'accuracy': 1 - mae,  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Å–∏—è
                                    'training_time': sub_data.get('training_time', 0),
                                    'type': 'classical'
                                }
                else:
                    # –î–ª—è SOTA –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º validation loss
                    val_loss = model_data.get('val_metrics', {}).get('final_val_loss', float('inf'))
                    if val_loss < best_score:
                        best_score = val_loss
                        best_model = {
                            'name': model_name,
                            'accuracy': 1 - val_loss,  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Å–∏—è
                            'training_time': model_data.get('training_time', 0),
                            'type': 'SOTA'
                        }
        
        return best_model
    
    def run_full_pipeline(self, models: List[str], quick_mode: bool = False) -> bool:
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        print("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –ü–ê–ô–ü–õ–ê–ô–ù–ê –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –ó–ê–°–£–•–ò")
        print("=" * 60)
        
        total_start = time.time()
        
        # –≠—Ç–∞–ø 1: –°–±–æ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        if not self.run_data_pipeline(quick_mode):
            print("‚ùå –ü–∞–π–ø–ª–∞–π–Ω –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ —ç—Ç–∞–ø–µ —Å–±–æ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
            return False
        
        # –≠—Ç–∞–ø 2: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        if not self.run_training_pipeline(models, quick_mode):
            print("‚ùå –ü–∞–π–ø–ª–∞–π–Ω –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ —ç—Ç–∞–ø–µ –æ–±—É—á–µ–Ω–∏—è")
            return False
        
        # –≠—Ç–∞–ø 3: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if not self.create_final_report():
            print("‚ö† –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞")
        
        total_time = time.time() - total_start
        
        print("\n" + "üéâ" * 20)
        print("–ü–ê–ô–ü–õ–ê–ô–ù –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
        print("üéâ" * 20)
        print(f"‚è± –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_time/60:.1f} –º–∏–Ω—É—Ç")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.project_root / 'results'}")
        
        return True
    
    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        print("üßπ –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
        
        temp_dirs = [
            self.project_root / "outputs",
            self.project_root / ".hydra"
        ]
        
        for temp_dir in temp_dirs:
            if temp_dir.exists():
                import shutil
                shutil.rmtree(temp_dir)
                print(f"  –£–¥–∞–ª–µ–Ω–æ: {temp_dir}")
        
        print("‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(
        description="–°–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–∞—Å—É—Ö–∏ - –≥–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python run_project.py --quick                    # –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –≤—Å–µ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞
  python run_project.py --full                     # –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Å–æ –≤—Å–µ–º–∏ –º–æ–¥–µ–ª—è–º–∏
  python run_project.py --data-only                # –¢–æ–ª—å–∫–æ —Å–±–æ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
  python run_project.py --train-only --model rf    # –¢–æ–ª—å–∫–æ –æ–±—É—á–µ–Ω–∏–µ Random Forest
  python run_project.py --custom --config my.yaml  # –ö–∞—Å—Ç–æ–º–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        """
    )
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∂–∏–º—ã
    mode_group = parser.add_mutually_exclusive_group(required=True)
    mode_group.add_argument('--quick', action='store_true',
                           help='–ë—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫ (—É—Ä–µ–∑–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –º–æ–¥–µ–ª–∏)')
    mode_group.add_argument('--full', action='store_true',
                           help='–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Å–æ –≤—Å–µ–º–∏ –º–æ–¥–µ–ª—è–º–∏')
    mode_group.add_argument('--data-only', action='store_true',
                           help='–¢–æ–ª—å–∫–æ —Å–±–æ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö')
    mode_group.add_argument('--train-only', action='store_true',
                           help='–¢–æ–ª—å–∫–æ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π')
    mode_group.add_argument('--custom', action='store_true',
                           help='–ö–∞—Å—Ç–æ–º–Ω—ã–π —Ä–µ–∂–∏–º —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π')
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument('--model', choices=['all', 'classical', 'earthformer', 'convlstm', 'tft', 'unet'],
                       default='all', help='–ú–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è')
    parser.add_argument('--config', type=str, help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏')
    parser.add_argument('--no-cleanup', action='store_true',
                       help='–ù–µ —É–¥–∞–ª—è—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã')
    parser.add_argument('--save-config', type=str,
                       help='–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ —Ñ–∞–π–ª')
    
    args = parser.parse_args()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    runner = ProjectRunner()
    
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        if not runner.check_environment():
            return 1
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        runner.load_config(args.config)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ)
        if args.save_config:
            runner.save_config(args.save_config)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        if args.model == 'all':
            models = ['classical', 'earthformer', 'convlstm', 'tft', 'unet']
        elif args.model == 'classical':
            models = ['classical']
        else:
            models = [args.model]
        
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
        success = False
        
        if args.quick:
            print("‚ö° –ë–´–°–¢–†–´–ô –†–ï–ñ–ò–ú")
            success = runner.run_full_pipeline(['classical'], quick_mode=True)
            
        elif args.full:
            print("üî• –ü–û–õ–ù–´–ô –†–ï–ñ–ò–ú")
            success = runner.run_full_pipeline(models, quick_mode=False)
            
        elif args.data_only:
            print("üì¶ –¢–û–õ–¨–ö–û –°–ë–û–†–ö–ê –î–ê–ù–ù–´–•")
            success = runner.run_data_pipeline(quick_mode=args.quick)
            
        elif args.train_only:
            print("ü§ñ –¢–û–õ–¨–ö–û –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
            success = runner.run_training_pipeline(models, quick_mode=False)
            
        elif args.custom:
            print("‚öôÔ∏è –ö–ê–°–¢–û–ú–ù–´–ô –†–ï–ñ–ò–ú")
            # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä —ç—Ç–∞–ø–æ–≤
            print("–í—ã–±–µ—Ä–∏—Ç–µ —ç—Ç–∞–ø—ã –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:")
            print("1. –°–±–æ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
            print("2. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
            print("3. –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞")
            
            stages = input("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä–∞ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1,2,3): ").strip()
            
            success = True
            if '1' in stages:
                success = success and runner.run_data_pipeline()
            if '2' in stages and success:
                success = success and runner.run_training_pipeline(models)
            if '3' in stages and success:
                success = success and runner.create_final_report()
        
        # –û—á–∏—Å—Ç–∫–∞
        if not args.no_cleanup:
            runner.cleanup()
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å
        if success:
            print(f"\nüéâ –ü—Ä–æ–µ–∫—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            return 0
        else:
            print(f"\n‚ùå –ü—Ä–æ–µ–∫—Ç –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–∞–º–∏")
            return 1
            
    except KeyboardInterrupt:
        print("\n‚èπ –ü—Ä–æ–µ–∫—Ç –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return 1
    except Exception as e:
        print(f"\nüí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        return 1

if __name__ == "__main__":
    exit(main())